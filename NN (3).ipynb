{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris['data'],\n",
    "iris['target'], random_state=2409)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing iris dataset and spliting it into trainning set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.     ,  0.     ,  0.99539, -0.05889,  0.85243,  0.02306,\n",
       "         0.83398, -0.37708,  1.     ,  0.0376 ,  0.85243, -0.17755,\n",
       "         0.59755, -0.44945,  0.60536, -0.38223,  0.84356, -0.38542,\n",
       "         0.58212, -0.32192,  0.56971, -0.29674,  0.36946, -0.47357,\n",
       "         0.56811, -0.51171,  0.41078, -0.46168,  0.21266, -0.3409 ,\n",
       "         0.42267, -0.54487,  0.18641, -0.453  ,  1.     ],\n",
       "       [ 1.     ,  0.     ,  1.     , -0.18829,  0.93035, -0.36156,\n",
       "        -0.10868, -0.93597,  1.     , -0.04549,  0.50874, -0.67743,\n",
       "         0.34432, -0.69707, -0.51685, -0.97515,  0.05499, -0.62237,\n",
       "         0.33109, -1.     , -0.13151, -0.453  , -0.18056, -0.35734,\n",
       "        -0.20332, -0.26569, -0.20468, -0.18401, -0.1904 , -0.11593,\n",
       "        -0.16626, -0.06288, -0.13738, -0.02447, -1.     ],\n",
       "       [ 1.     ,  0.     ,  1.     , -0.03365,  1.     ,  0.00485,\n",
       "         1.     , -0.12062,  0.88965,  0.01198,  0.73082,  0.05346,\n",
       "         0.85443,  0.00827,  0.54591,  0.00299,  0.83775, -0.13644,\n",
       "         0.75535, -0.0854 ,  0.70887, -0.27502,  0.43385, -0.12062,\n",
       "         0.57528, -0.4022 ,  0.58984, -0.22145,  0.431  , -0.17365,\n",
       "         0.60436, -0.2418 ,  0.56045, -0.38238,  1.     ]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\")\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing ionosphere from text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.     ,  0.     ,  0.99539, -0.05889,  0.85243,  0.02306,\n",
       "         0.83398, -0.37708,  1.     ,  0.0376 ,  0.85243, -0.17755,\n",
       "         0.59755, -0.44945,  0.60536, -0.38223,  0.84356, -0.38542,\n",
       "         0.58212, -0.32192,  0.56971, -0.29674,  0.36946, -0.47357,\n",
       "         0.56811, -0.51171,  0.41078, -0.46168,  0.21266, -0.3409 ,\n",
       "         0.42267, -0.54487,  0.18641, -0.453  ],\n",
       "       [ 1.     ,  0.     ,  1.     , -0.18829,  0.93035, -0.36156,\n",
       "        -0.10868, -0.93597,  1.     , -0.04549,  0.50874, -0.67743,\n",
       "         0.34432, -0.69707, -0.51685, -0.97515,  0.05499, -0.62237,\n",
       "         0.33109, -1.     , -0.13151, -0.453  , -0.18056, -0.35734,\n",
       "        -0.20332, -0.26569, -0.20468, -0.18401, -0.1904 , -0.11593,\n",
       "        -0.16626, -0.06288, -0.13738, -0.02447],\n",
       "       [ 1.     ,  0.     ,  1.     , -0.03365,  1.     ,  0.00485,\n",
       "         1.     , -0.12062,  0.88965,  0.01198,  0.73082,  0.05346,\n",
       "         0.85443,  0.00827,  0.54591,  0.00299,  0.83775, -0.13644,\n",
       "         0.75535, -0.0854 ,  0.70887, -0.27502,  0.43385, -0.12062,\n",
       "         0.57528, -0.4022 ,  0.58984, -0.22145,  0.431  , -0.17365,\n",
       "         0.60436, -0.2418 ,  0.56045, -0.38238]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\",\n",
    "usecols=np.arange(34))\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\",\n",
    "usecols=34, dtype='int')\n",
    "y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, y, random_state=2409)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 4)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 4)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def E_len(row1, row2):   \n",
    "    distance = 0\n",
    "    for i in range(len(row1)-1):     \n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "computing Euclidean distance between two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.23606797749979, 0)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def get_Neighbour(row1,row2):\n",
    "    current_n = math.inf\n",
    "    for n in range(row2.shape[0]):\n",
    "        dist = E_len(row1,row2[n])\n",
    "        if dist < current_n:\n",
    "            current_n = dist\n",
    "            neighbors = n\n",
    "        return current_n, neighbors\n",
    "    # test code to see if it works\n",
    "get_Neighbour(np.array([1,2,3]),np.zeros((3,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finds the nearest neighbour to from one to another\n",
    "implemented using lab 3 but substituting current_min of current n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0\n",
      "Error: 1\n",
      "Error: 3\n",
      "Error: 4\n",
      "Error: 5\n",
      "Error: 7\n",
      "Error: 8\n",
      "Error: 11\n",
      "Error: 12\n",
      "Error: 13\n",
      "Error: 14\n",
      "Error: 15\n",
      "Error: 17\n",
      "Error: 18\n",
      "Error: 19\n",
      "Error: 21\n",
      "Error: 24\n",
      "Error: 25\n",
      "Error: 26\n",
      "Error: 28\n",
      "Error: 31\n",
      "Error: 35\n",
      "Error: 36\n",
      "Error: 37\n",
      "Errors found: 24\n",
      "The error rate is 0.631578947368421\n"
     ]
    }
   ],
   "source": [
    "iris_test = X_test.shape[0]\n",
    "count = 0\n",
    "# to count the number of errors \n",
    "estimate = np.zeros(iris_test,dtype=int)\n",
    "for n in range(iris_test):\n",
    "  estimate[n] = y_train[get_Neighbour(X_test[n],X_train)[1]]\n",
    "  if estimate[n] != y_test[n]:\n",
    "    count = count + 1\n",
    "    print(\"Error:\",n)\n",
    "print(\"Errors found:\",count)\n",
    "print(\"The error rate is\",(count / iris_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying getNeighbors func to test set over each sample\n",
    "\n",
    "also implemented using lab 3 but intead trainning and for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking the estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1\n",
      "Error: 3\n",
      "Error: 7\n",
      "Error: 9\n",
      "Error: 11\n",
      "Error: 12\n",
      "Error: 14\n",
      "Error: 17\n",
      "Error: 19\n",
      "Error: 20\n",
      "Error: 23\n",
      "Error: 24\n",
      "Error: 26\n",
      "Error: 28\n",
      "Error: 30\n",
      "Error: 31\n",
      "Error: 33\n",
      "Error: 34\n",
      "Error: 36\n",
      "Error: 39\n",
      "Error: 41\n",
      "Error: 48\n",
      "Error: 49\n",
      "Error: 52\n",
      "Error: 53\n",
      "Error: 55\n",
      "Error: 59\n",
      "Error: 67\n",
      "Error: 68\n",
      "Error: 69\n",
      "Error: 70\n",
      "Error: 74\n",
      "Error: 75\n",
      "Error: 81\n",
      "Error: 82\n",
      "Error: 87\n",
      "Errors found: 36\n",
      "The error rate is 0.4090909090909091\n"
     ]
    }
   ],
   "source": [
    "ion_test = X1_test.shape[0]\n",
    "# to count the number of errors\n",
    "count = 0\n",
    "for n in range(ion_test):\n",
    "\n",
    "    # define estimate\n",
    "    estimate = y1_train[get_Neighbour(X1_test[n],X1_test)[1]]\n",
    "    if estimate != y1_train[n]:\n",
    "        print(\"Error:\",n)\n",
    "        count = count + 1\n",
    "print(\"Errors found:\",count)\n",
    "print(\"The error rate is\",(count / ion_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest Neighbour implementation for ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conformityPredictor(data,label,n):\n",
    "  current_n = neighbor = math.inf\n",
    "  for i in range(data.shape[0]):\n",
    "\n",
    "        # stores euclidean distance between data to each other\n",
    "        dist = E_len(data[n],data[i])\n",
    "        if (dist < current_n) & (label[i]==label[n]) & (i!=n):\n",
    "          current_n = dist\n",
    "        if (dist < neighbor) & (label[i]!=label[n]) & (i!=n):\n",
    "          current_n = dist\n",
    "        # acts as a base case\n",
    "        if current_n == 0:\n",
    "            if (neighbor == 0):\n",
    "              print(\"0/0\")    \n",
    "              return 0                 \n",
    "            return math.inf\n",
    "  else:\n",
    "    return neighbor / current_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Here we want to test the confomity score of the nth element both the \n",
    "    data and the label have been identified and stated use of if condition to find current distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  0\n",
      "Error:  2\n",
      "Error:  3\n",
      "Error:  5\n",
      "Error:  6\n",
      "Error:  7\n",
      "Error:  8\n",
      "Error:  9\n",
      "Error:  10\n",
      "Error:  11\n",
      "Error:  13\n",
      "Error:  16\n",
      "Error:  17\n",
      "Error:  19\n",
      "Error:  20\n",
      "Error:  22\n",
      "Error:  23\n",
      "Error:  24\n",
      "Error:  27\n",
      "Error:  28\n",
      "Error:  29\n",
      "Error:  30\n",
      "Error:  31\n",
      "Error:  32\n",
      "Error:  33\n",
      "Error:  34\n",
      "Error:  36\n",
      "Error:  37\n",
      "Errors found:  28\n",
      "Average false p-value:  0.7368421052631579\n"
     ]
    }
   ],
   "source": [
    "iris_train = X_train.shape[0]\n",
    "iris_test = X_test.shape[0]\n",
    "\n",
    "# the sum of the p values\n",
    "p_value_count = 0.0\n",
    "count = 0\n",
    "# stores the conformity score\n",
    "conformity_score = np.zeros(iris_train+1)  # the conformity scores\n",
    "# p-values\n",
    "p_value = np.zeros(3)\n",
    "# need to define the type\n",
    "estimate = np.zeros(iris_test,dtype=int)\n",
    "\n",
    "for n in range(iris_test):\n",
    "    # Stack arrays in sequence vertically\n",
    "    modifiedX = np.row_stack((X_train,X_test[n]))\n",
    "    for i in range(3): \n",
    "        modifiedY = np.append(y_train,i)\n",
    "        for j in range(iris_train+1):\n",
    "            conformity_score[j] = conformityPredictor(modifiedX,modifiedY,j)\n",
    "        # p-value for i \n",
    "        p_value[i] = np.mean(conformity_score<=conformity_score[iris_train])  \n",
    "    estimate[n] = np.argmax(p_value)   \n",
    "    if estimate[n] != y_test[n]:\n",
    "        count = count + 1\n",
    "        print(\"Error: \",n)\n",
    "\n",
    "\n",
    "        # adds the sum of p values together\n",
    "        p_value_count = p_value_count + p_value[0] + p_value[1] + p_value[2] - p_value[y_test[n]]\n",
    "print(\"Errors found: \", count)\n",
    "print(\"Average false p-value: \", p_value_count/(2*iris_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conformity predictor for iris\n",
    "here we calculate and tally up the p values to find an overall sum to help calculate the average p value, whilst also fidning the number of errors detected "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief Discussion\n",
    "\n",
    "In this case we case see that the nearest neighbour and comformity version have \n",
    "a different number of errors. Looking at the test sameples the errors are often \n",
    "different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
